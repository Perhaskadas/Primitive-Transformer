num_heads = 8 # Number of attention heads in encoder/decoder
n_hidden = 512 # Number of hidden units in the feed forward network
layers = 6 # Number of encoder/decoder layers
vocab_size = 35000 # Number of words in the english-german vocabulary
dropout = 0.1 # Dropout rate
batch_size = 25000 # max number of tokens in a batch

